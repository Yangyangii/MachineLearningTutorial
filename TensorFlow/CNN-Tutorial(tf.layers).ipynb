{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1' # for using only cpu\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.contrib.learn.datasets.load_dataset('mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_cnn(features, labels, mode):\n",
    "    # Model Architecture(Network)\n",
    "    reshape_images = tf.reshape(features, [-1, 28, 28, 1])\n",
    "\n",
    "    conv1 = tf.layers.conv2d(reshape_images, 32, [3, 3], activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(conv1, [3, 3], [2, 2])\n",
    "\n",
    "    conv2 = tf.layers.conv2d(pool1, 64, [3, 3], activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(conv2, [3, 3], [2, 2])\n",
    "\n",
    "    flatten_feature = tf.contrib.layers.flatten(pool2)\n",
    "    dense1 = tf.layers.dense(flatten_feature, 1024, activation=tf.nn.relu)\n",
    "    drop1 = tf.layers.dropout(dense1, 0.5, training = (mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    logits = tf.layers.dense(drop1, 10, activation=None)\n",
    "    \n",
    "    predictions = {\n",
    "        'classes': tf.argmax(logits, axis=1),\n",
    "        'probabilities': tf.nn.softmax(logits, name='softmax_tensor')\n",
    "    } # for log\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=labels)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        LEARNING_RATE = 1e-4\n",
    "        opt = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=opt)\n",
    "    \n",
    "    eval_metric_ops = {\n",
    "        'accuracy': tf.metrics.accuracy(labels=labels, predictions=predictions['classes'])\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.layers method의 parameter\n",
    "\n",
    "tf.layers.conv2d(input_vector, output_channel, [kernel_width, kernel_height], ...)\n",
    "\n",
    "tf.layers.max_pooling2d(input_vector, [kernel_width, kernel_height], [strides_along_width, strides_along_height], ...)\n",
    "\n",
    "tf.layers.dense(input_vector, output_channel, ...)\n",
    "\n",
    "tf.layers.dropout(input_vector, drop_ratio, training, ...)\n",
    "\n",
    "위의 기본적인 함수 외에도 Batch normalization이나 몇 가지를 매우 간편하게 제공한다. (BN은 확실히 tf.nn 보다 편하다)\n",
    "\n",
    "최근에는 TF 공식 다큐먼트 튜토리얼에서  tf.nn이 아닌 tf.layers를 통한 개발을 적극 권장하는 중..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.estimator\n",
    "tf.estimator는 PREDICT / TRAIN / EVAL 이라는 MODE에 따라 모델을 간편하게 쓸 수 있도록 지원하는 High-level API이다.\n",
    "\n",
    "처음에는 이런저런 조건을 맞춰야해서 조금 더 헷갈릴 수 있으나 익숙해지면 오히려 골격만 맞춰주되 자잘한 부분들에 있어 상당히 편해진다\n",
    "\n",
    "특히 모델의 graph를 저장하고 불러오는 기능을 자동으로 해주고, iteration에 따른 log를 해주는 부분이 편리하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_global_id_in_cluster': 0, '_task_id': 0, '_model_dir': 'tmp/mnist_net', '_session_config': None, '_master': '', '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_save_checkpoints_steps': None, '_save_summary_steps': 100, '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000022E52DD8668>, '_is_chief': True, '_service': None, '_save_checkpoints_secs': 600, '_num_worker_replicas': 1, '_task_type': 'worker', '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "mnist_net = tf.estimator.Estimator(model_fn=my_cnn, model_dir='tmp/mnist_net')\n",
    "# tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "# logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50) # Not used my simple code. Use for only log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(x=mnist.train.images, y=mnist.train.labels.astype(np.int32),\n",
    "                                                    batch_size=64, num_epochs=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tmp/mnist_net\\model.ckpt-300\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 301 into tmp/mnist_net\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.45215362, step = 301\n",
      "INFO:tensorflow:global_step/sec: 24.1083\n",
      "INFO:tensorflow:loss = 0.23355797, step = 401 (4.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7963\n",
      "INFO:tensorflow:loss = 0.29789072, step = 501 (4.033 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 600 into tmp/mnist_net\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.14420754.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x22e52dd8550>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_net.train(input_fn=train_input_fn, steps=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(x=mnist.test.images, y=mnist.test.labels.astype(np.int32),\n",
    "                                                   num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-31-11:54:09\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from tmp/mnist_net\\model.ckpt-600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-31-11:54:11\n",
      "INFO:tensorflow:Saving dict for global step 600: accuracy = 0.9585, global_step = 600, loss = 0.14456593\n",
      "{'loss': 0.14456593, 'accuracy': 0.9585, 'global_step': 600}\n"
     ]
    }
   ],
   "source": [
    "eval_results = mnist_net.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
