{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뉴럴넷과 CNN에 대해 기본적인 강의를 듣고 기초지식을 가지고 있다는 가정하에 진행되는 튜토리얼입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yangyangii\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1' # for using only cpu\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([2],dtype=tf.float32)\n",
    "b = tf.constant([3],dtype=tf.float32)\n",
    "c = tf.constant([4],dtype=tf.float32)\n",
    "\n",
    "op = a*b+c\n",
    "# op = tf.add(tf.multiply(a,b), c)\n",
    "\n",
    "sess = tf.Session()\n",
    "result = sess.run(op)\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.constant는 텐서플로우에서 상수값으로 사용하기 위한 타입입니다.\n",
    "코드를 보면 각각 a, b, c가 2, 3, 4라는 값으로 데이터 타입은 float32로 할당되었습니다.\n",
    "이 상수값을 가진 텐서를 통해 a*b+c라는 operation을 구현해서 op라는 이름으로 저장합니다.\n",
    "\n",
    "여기서는 간단히 연산 기호를 통해 구현했지만, 실제로는 주석에 있는 tf.add와 tf.multiply라는 operation 함수로 매칭됩니다.\n",
    "또한 텐서플로우는 Session을 통해 그래프를 작동시키는데, 이를 위해 필요한 가장 간단한 함수들을 볼 숫 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7]\n",
      "[[-1. -1. -1.]\n",
      " [-1. -1. -1.]]\n",
      "Tensor(\"Const_3:0\", shape=(7,), dtype=int32)\n",
      "Tensor(\"Const_4:0\", shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Constant 1-D Tensor populated with value list.\n",
    "tensor1 = tf.constant([1, 2, 3, 4, 5, 6, 7]) # [1 2 3 4 5 6 7]\n",
    "\n",
    "# Constant 2-D tensor populated with scalar value -1.\n",
    "tensor2 = tf.constant(-1.0, shape=[2, 3]) # [[-1. -1. -1.], [-1. -1. -1.]]\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run(tensor1))\n",
    "print(sess.run(tensor2))\n",
    "print(tensor1)\n",
    "print(tensor2)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 코드는 tf.constant를 사용하되 Rank와 Shape의 크기를 늘린 예시입니다.\n",
    "단순히 텐서를 실행했을 때의 결과물을 볼 수 있습니다.\n",
    "\n",
    "뉴럴넷은 대부분 행렬 연산을 통해 이루어지기 때문에, 이러한 2차원 3차원들에 대해 익숙해 지시면 용이할 것 같습니다.\n",
    "\n",
    "텐서 자체를 프린트 했을 때의 내용을 보면, 각 텐서의 shape과 data dtype을 확인할 수 있습니다. 뉴럴넷에서 연산을 프로그래밍 할 때는 이 shape을 계속해서 주의하면서 모델을 구축해줘야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  4.  6.  8. 10.]\n"
     ]
    }
   ],
   "source": [
    "input_data = [1,2,3,4,5]\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32)\n",
    "k = tf.constant(2, dtype=tf.float32)\n",
    "y = x * k\n",
    "\n",
    "sess = tf.Session()\n",
    "result = sess.run(y, feed_dict={x:input_data})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 tf.placeholder를 통해 feed를 하는 예시입니다.\n",
    "먼저 x라는 placeholder 텐서를 만들고 operation을 만든 다음에 최종적으로 세션을 실행 할 때 feed_dict에서 placeholder에 어떤 데이터를 넣을지 정해주는 코드입니다.\n",
    "\n",
    "x의 shape이 정해져있지 않으므로 스칼라로 취급되며, 각각의 input data 스칼라에 constant 2를 곱하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  20.   40.   60.   80.  100.]\n"
     ]
    }
   ],
   "source": [
    "input_data = [1,2,3,4,5]\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32)\n",
    "W = tf.Variable([10],dtype=tf.float32)\n",
    "W = W.assign_add([10.0])\n",
    "y = W*x\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "result = sess.run(y, feed_dict={x:input_data})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.Variable은 말 그대로 변수로 사용하기 위한 텐서입니다.\n",
    "주로 학습에 사용되는 parameter를 만드는데 사용됩니다.\n",
    "\n",
    "tf.Variable은 사용하기에 앞서 반드시 초기화가 필요합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코드는 tf.Variable을 사용하기 위해 초기화를 추가한 것과, tf.Variable을 통해 만든 W가 값이 변할수 있다는 것을 보여준 코드입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST w/ Single Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본격적으로 뉴럴넷을 구현하기 위한 모델 구축에 들어갑니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yangyangii\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-7-df9e97748cf2>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\yangyangii\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\yangyangii\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\yangyangii\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\yangyangii\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\yangyangii\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAhElEQVR4nNWRSxICIQxEX1nea+LJ\njCcLnqxdwAAjnyqX9pJHd9IA/yt3SWFTpCIfWaiqnNwrE8ArQYCli81CUh7WnP28zKwNvXUXnjkC\nOK5OK3t6v9A3lWr+vEqcJ60KD8wOA96jsWbHnOXkHfNN6IKxqgHlxxaM2ITiQ4vu4dOy/u/6AHLl\nduTLFPT8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x190C03BD048>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.misc.toimage(mnist.train.images[999].reshape((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코드들은 우리가 뉴럴넷에 사용할 MNIST 데이터를 가져오고, 데이터가 정상적으로 들어가 있는지 확인해보는 코드입니다.\n",
    "\n",
    "MNIST 데이터는 손글씨 digit 데이터로 (28,28)의 shape을 갖춘 gray scale 이미지 입니다.\n",
    "여기서 텐서플로우에 내장된 mnist 데이터를 가져오는 함수를 통해 가져오게 되면, 다운받아져 있지 않은 경우 다운로드를 하게 되며, 함수의 첫번째 parameter에 해당하는 경로에 다운을 받습니다.\n",
    "\n",
    "one_hot의 경우 classifier에 쓰기 위해 label의 종류만큼 size를 정하고 label에 해당하는 곳에만 sparse하게 1을 부여하는 encoding을 하게 되는데, digit의 경우 0-9까지 10가지가 있으므로 shape이 [10]이라고 생각하시면 되겠습니다. 예시를 보시면 쉽게 이해할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "labels = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.truncated_normal([784, 10], stddev=0.1))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "images와 labels는 우리가 MNIST 데이터를 순차적으로 집어넣을 것이므로 tf.placeholder를 통해 만드는데, 학습할 때 MNIST 데이터를 하나씩만 하는 것이 아니라 mini-batch size만큼씩 병렬처리할 것이므로 mini-batch size만큼 shape을 정해주면 되는데, 텐서플로우는 placeholder에서 python의 None 타입을 통해서 추후에 mini-batch size만큼 자동할당 되도록 돕고 있습니다. 따라서 우리는 여기서는 None으로 해놓고 뒤에서 mini-batch size를 정할 겁니다.\n",
    "\n",
    "W와 b는 Weight와 bias입니다. 뉴럴넷에서 배운 학습 parameter인데 우리는 간단한 singe layer perceptron을 위해 input image의 size인 784와 output의 size인 10에 대해 weight와 bias의 shape을 정하고 각각 텐서를 만듭니다.\n",
    "\n",
    "tf.truncated_normal은 랜덤함수를 통해 표준편차 0.1에서 아웃라이어를 잘라낸 상태의 값으로 shape에 맞춰져 있는 텐서를 리턴합니다.\n",
    "\n",
    "tf.zeros는 shape에 맞춰 모든 값을 0으로 되어있는 텐서를 리턴합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit = tf.nn.softmax(tf.matmul(images, W) + b)\n",
    "loss = -tf.reduce_sum(labels*tf.log(logit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.matmul은 행렬곱 함수이며, image와 W를 행렬곱 하고 bias를 더한 다음에 softmax를 취하는 operation을 logit에 저장합니다.\n",
    "\n",
    "loss는 cross entropy 식으로 구현했고, tf.reduce_sum은 axis에 따라 텐서의 모든 값을 더해서 차원을 줄이고 리턴하는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습에 사용되는 optimizer로는 기본적인 Gradient Descent를 사용하고, learning rate는 0.01로 설정합니다.\n",
    "\n",
    "또한, cross entropy loss를 minimize하는 방식으로 최적화해야하기 때문에 minimize 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_op, feed_dict={images: batch_xs, labels: batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1천번 학습을 시킬텐데 1번의 iteration마다 mini-batch size가 100이므로 100개의 example을 보고나서 최적화 update를 한 번 합니다.\n",
    "\n",
    "batch_xs와 batch_ys에는 각각 100개의 이미지([100, 784])와 Label([100, 10])이 들어가 있고, iteration마다 다음 mini-batch의 값을 꺼내서 placeholder에 feed 하도록 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logit, axis=1), tf.argmax(labels, axis=1))\n",
    "acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 모델의 학습을 통해 성능이 얼마나 좋아졌는지 확인하는 단계입니다.\n",
    "\n",
    "성능을 판단하기 위한 함수를 만들기 위해 모델의 아웃풋과 label이 얼마나 일치하는지 확인합니다.\n",
    "\n",
    "tf.argmax는 axis를 기준으로 각각 가장 큰 값의 index를 리턴하는 함수입니다.\n",
    "\n",
    "tf.equal은 두 Tensor의 element들이 일치하는지에 대해 Bool type을 리턴하는 함수입니다.\n",
    "\n",
    "tf.reduce_mean은 axis를 기준으로 평균을 구하는 함수이며, 평균을 위해서 float 타입만 취급하기 때문에 이전에 tf.cast를 통해 타입을 float로 변경해 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89910907\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(acc, feed_dict={images: mnist.train.images, labels: mnist.train.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9032\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(acc, feed_dict={images: mnist.test.images, labels: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각 Training Set Accuracy, Test Set Accuracy 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "labels = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "# W = tf.Variable(tf.zeros([784, 10]))\n",
    "W1 = tf.Variable(tf.truncated_normal([784, 100], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([100]))\n",
    "W2 = tf.Variable(tf.truncated_normal([100, 10], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out1 = tf.nn.relu(tf.matmul(images, W1) + b1)\n",
    "logit = tf.matmul(out1, W2) + b2\n",
    "# loss = -tf.reduce_sum(labels*tf.log(logit))\n",
    "# loss = tf.nn.softmax_cross_entropy_with_logits()\n",
    "loss = tf.reduce_sum(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logit)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146.492\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100, shuffle=True)\n",
    "    _, batch_loss = sess.run([train_op, loss], feed_dict={images: batch_xs, labels: batch_ys})\n",
    "print(batch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = tf.reduce_mean(tf.cast(\n",
    "    tf.equal(tf.argmax(logit, axis=1), tf.argmax(labels, axis=1)),\n",
    "    tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.991273\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(acc, feed_dict={images: mnist.train.images, labels: mnist.train.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9769\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(acc, feed_dict={images: mnist.test.images, labels: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실습! 성능 높이기: 15분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST w/ CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN 부터는 모델이 조금씩 복잡해지므로 단순화 시킬 수 있는 부분들에 대해서는 함수나 클래스로 reusable하게 만드는 것이 중요합니다.\n",
    "\n",
    "weight와 bias를 만드는 부분은 모든 레이어에 대해 필요한 부분이며, 대부분 단순 반복하고 shape만 달라지므로 shape을 parameter로 기본적인 함수를 정의합니다. MLP에서 구현했던 것과 거의 동일합니다.\n",
    "\n",
    "0.1로 bias를 초기화하는 이유는 non-linear activation function으로 ReLU를 사용할 경우 죽는 Neuron이 발생하는 것을 방지하기 위해서입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.nn.conv2d와 tf.nn.max_pool은 Convolutional layer와 Maxpooling layer를 구현하는 함수입니다.\n",
    "\n",
    "tf.nn.conv2d는 2-dim input을 기준으로 input x가 들어왔을 때 W를 기준으로 kernel을 구성하여 multiple convolution을 한 아웃풋을 리턴합니다. padding은 zero padding을 설정하는 parameter이고 'SAME'일 경우 shape을 유지시키고 'VALID'의 경우 padding없이 유효한 값에 대해서만 연산합니다. strides는 리스트의 첫번째와 마지막은 batch와 depth를 나타내므로 convoltion을 할 때는 무조건 1로 설정한다고 생각하시면 되고, 2번째와 3번째는 각각 height와 width의 stride를 설정해주시면 됩니다. 여기서 우리는 간단한 CNN을 구현할 것이기 때문에 stride는 1로 설정하고 feature map의 size는 max pooling layer를 통해 줄이도록 합니다.\n",
    "\n",
    "tf.nn.max_pool은 input x에 대해 max-pooling을 적용하며, ksize는 커널의 사이즈를 의미합니다. 마찬가지로 2번째와 3번째가 height와 width이므로, height와 width를 2씩, stride 또한 2씩 설정합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "reshape_images = tf.reshape(images, [-1, 28, 28, 1])\n",
    "\n",
    "labels = tf.placeholder(shape=[None, 10], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적으로 input과 label을 placeholder를 통해 받아들이는 부분은 동일하나, Convolution 연산을 위해서는 2차원이어야 하고 텐서플로우의 conv2d 함수는 4차원 텐서를 인풋으로 받기 때문에, tf.reshape을 통해 dimension을 조정해줍니다.\n",
    "\n",
    "conv2d는 4-D Tensor를 input으로 받는데 리스트의 첫번째인 -1은 mini-batch size에 따라 자동적으로 설정되게 하는 부분이며, 마지막의 1은 gray scale이므로 depth 1을 넣습니다. RGB image의 경우 3이 들어가게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5,5,1,32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "W_conv2 = weight_variable([5,5,32,64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "W_fc1 = weight_variable([7*7*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight와 bias는 설계한 모델에 따라 shape을 맞춰서 만들어주면 됩니다.\n",
    "\n",
    "Weight는 4 rank의 shape으로 구성되는데, 앞의 둘은 kernel의 height와 width라고 생각하면 되고, input channel, output channel의 size라고 생각하시면 됩니다.\n",
    "\n",
    "bias는 output channel의 size입니다.\n",
    "\n",
    "max-pooling의 경우 weight가 필요하지 않으므로 따로 설정하지 않고, Fully-connected layer에 대해 weight와 bias를 설정하면 됩니다. 이는 MLP에서 한 부분과 동일합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layer1 = tf.nn.relu(conv(reshape_images, W_conv1) + b_conv1)\n",
    "pool_layer1 = max_pool(conv_layer1)\n",
    "\n",
    "conv_layer2 = tf.nn.relu(conv(pool_layer1, W_conv2) + b_conv2)\n",
    "pool_layer2 = max_pool(conv_layer2)\n",
    "\n",
    "pool2_flat = tf.reshape(pool_layer2, [-1, 7*7*64])\n",
    "fc_layer1 = tf.nn.relu(tf.matmul(pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "drop_out = tf.nn.dropout(fc_layer1, keep_prob)\n",
    "\n",
    "logit = tf.matmul(drop_out, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 구현한 각 함수들과 학습 parameter들을 통해 레이어들을 구성하는 operation들입니다.\n",
    "convolutional layer에서는 ReLU 함수를 activation 함수로 사용했습니다.\n",
    "\n",
    "주의할 점은 Conv는 4-D Tensor가 input이지만 Fully-connected layer의 input은 2-D Tensor이므로 맞춰줘야한다.\n",
    "\n",
    "두번의 max-pooling layer를 거치게 되면 기존의 이미지가 [28,28]이고 stride가 2 이므로 [28,28] -> [14,14] -> [7,7]이 된다.\n",
    "\n",
    "[7,7]의 feature map이 마지막 channel의 개수 64개만큼 있으므로 총 7*7*64개의 노드가 있다.\n",
    "\n",
    "-1은 mini-batch size만큼 해당 노드 수로 쫙 펼쳐준 것이다.\n",
    "\n",
    "Convolution -> ReLU -> Max-pooling\n",
    "-> Convolution -> ReLU -> Max-pooling\n",
    "-> Linear -> ReLU -> Dropout\n",
    "-> Linear -> Softmax\n",
    "\n",
    "위와 같은 순서로 진행되며, Softmax는 사실 위에 포함되어 있지 않고 아래 코드에서 진행된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-27-8bbe37ab3257>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "step 0, training accuracy 0.08\n",
      "test accuracy 0.068\n",
      "step 1, training accuracy 0.16\n",
      "step 2, training accuracy 0.08\n",
      "step 3, training accuracy 0.14\n",
      "step 4, training accuracy 0.16\n",
      "step 5, training accuracy 0.22\n",
      "step 6, training accuracy 0.14\n",
      "step 7, training accuracy 0.1\n",
      "step 8, training accuracy 0.18\n",
      "step 9, training accuracy 0.22\n",
      "step 10, training accuracy 0.18\n",
      "step 11, training accuracy 0.18\n",
      "step 12, training accuracy 0.18\n",
      "step 13, training accuracy 0.2\n",
      "step 14, training accuracy 0.24\n",
      "step 15, training accuracy 0.3\n",
      "step 16, training accuracy 0.28\n",
      "step 17, training accuracy 0.3\n",
      "step 18, training accuracy 0.36\n",
      "step 19, training accuracy 0.36\n",
      "step 20, training accuracy 0.34\n",
      "step 21, training accuracy 0.3\n",
      "step 22, training accuracy 0.52\n",
      "step 23, training accuracy 0.46\n",
      "step 24, training accuracy 0.3\n",
      "step 25, training accuracy 0.42\n",
      "step 26, training accuracy 0.48\n",
      "step 27, training accuracy 0.44\n",
      "step 28, training accuracy 0.52\n",
      "step 29, training accuracy 0.54\n",
      "step 30, training accuracy 0.52\n",
      "step 31, training accuracy 0.46\n",
      "step 32, training accuracy 0.66\n",
      "step 33, training accuracy 0.64\n",
      "step 34, training accuracy 0.6\n",
      "step 35, training accuracy 0.56\n",
      "step 36, training accuracy 0.52\n",
      "step 37, training accuracy 0.62\n",
      "step 38, training accuracy 0.64\n",
      "step 39, training accuracy 0.56\n",
      "step 40, training accuracy 0.7\n",
      "step 41, training accuracy 0.58\n",
      "step 42, training accuracy 0.62\n",
      "step 43, training accuracy 0.62\n",
      "step 44, training accuracy 0.52\n",
      "step 45, training accuracy 0.78\n",
      "step 46, training accuracy 0.76\n",
      "step 47, training accuracy 0.76\n",
      "step 48, training accuracy 0.7\n",
      "step 49, training accuracy 0.78\n",
      "step 50, training accuracy 0.7\n",
      "step 51, training accuracy 0.78\n",
      "step 52, training accuracy 0.6\n",
      "step 53, training accuracy 0.82\n",
      "step 54, training accuracy 0.76\n",
      "step 55, training accuracy 0.7\n",
      "step 56, training accuracy 0.78\n",
      "step 57, training accuracy 0.74\n",
      "step 58, training accuracy 0.8\n",
      "step 59, training accuracy 0.72\n",
      "step 60, training accuracy 0.7\n",
      "step 61, training accuracy 0.74\n",
      "step 62, training accuracy 0.72\n",
      "step 63, training accuracy 0.7\n",
      "step 64, training accuracy 0.72\n",
      "step 65, training accuracy 0.74\n",
      "step 66, training accuracy 0.8\n",
      "step 67, training accuracy 0.74\n",
      "step 68, training accuracy 0.72\n",
      "step 69, training accuracy 0.68\n",
      "step 70, training accuracy 0.8\n",
      "step 71, training accuracy 0.78\n",
      "step 72, training accuracy 0.76\n",
      "step 73, training accuracy 0.84\n",
      "step 74, training accuracy 0.9\n",
      "step 75, training accuracy 0.78\n",
      "step 76, training accuracy 0.78\n",
      "step 77, training accuracy 0.84\n",
      "step 78, training accuracy 0.82\n",
      "step 79, training accuracy 0.8\n",
      "step 80, training accuracy 0.78\n",
      "step 81, training accuracy 0.9\n",
      "step 82, training accuracy 0.78\n",
      "step 83, training accuracy 0.8\n",
      "step 84, training accuracy 0.84\n",
      "step 85, training accuracy 0.78\n",
      "step 86, training accuracy 0.82\n",
      "step 87, training accuracy 0.74\n",
      "step 88, training accuracy 0.8\n",
      "step 89, training accuracy 0.8\n",
      "step 90, training accuracy 0.86\n",
      "step 91, training accuracy 0.82\n",
      "step 92, training accuracy 0.78\n",
      "step 93, training accuracy 0.84\n",
      "step 94, training accuracy 0.84\n",
      "step 95, training accuracy 0.82\n",
      "step 96, training accuracy 0.88\n",
      "step 97, training accuracy 0.86\n",
      "step 98, training accuracy 0.92\n",
      "step 99, training accuracy 0.86\n",
      "step 100, training accuracy 0.8\n",
      "test accuracy 0.8545\n",
      "step 101, training accuracy 0.78\n",
      "step 102, training accuracy 0.8\n",
      "step 103, training accuracy 0.82\n",
      "step 104, training accuracy 0.96\n",
      "step 105, training accuracy 0.86\n",
      "step 106, training accuracy 0.76\n",
      "step 107, training accuracy 0.84\n",
      "step 108, training accuracy 0.8\n",
      "step 109, training accuracy 0.88\n",
      "step 110, training accuracy 0.78\n",
      "step 111, training accuracy 0.76\n",
      "step 112, training accuracy 0.76\n",
      "step 113, training accuracy 0.86\n",
      "step 114, training accuracy 0.82\n",
      "step 115, training accuracy 0.76\n",
      "step 116, training accuracy 0.86\n",
      "step 117, training accuracy 0.82\n",
      "step 118, training accuracy 0.74\n",
      "step 119, training accuracy 0.84\n",
      "step 120, training accuracy 0.82\n",
      "step 121, training accuracy 0.8\n",
      "step 122, training accuracy 0.8\n",
      "step 123, training accuracy 0.88\n",
      "step 124, training accuracy 0.86\n",
      "step 125, training accuracy 0.9\n",
      "step 126, training accuracy 0.94\n",
      "step 127, training accuracy 0.98\n",
      "step 128, training accuracy 0.86\n",
      "step 129, training accuracy 0.94\n",
      "step 130, training accuracy 0.88\n",
      "step 131, training accuracy 0.9\n",
      "step 132, training accuracy 0.84\n",
      "step 133, training accuracy 0.82\n",
      "step 134, training accuracy 0.94\n",
      "step 135, training accuracy 0.92\n",
      "step 136, training accuracy 0.88\n",
      "step 137, training accuracy 0.92\n",
      "step 138, training accuracy 0.96\n",
      "step 139, training accuracy 0.88\n",
      "step 140, training accuracy 0.88\n",
      "step 141, training accuracy 0.9\n",
      "step 142, training accuracy 0.84\n",
      "step 143, training accuracy 0.94\n",
      "step 144, training accuracy 0.9\n",
      "step 145, training accuracy 0.9\n",
      "step 146, training accuracy 0.8\n",
      "step 147, training accuracy 0.74\n",
      "step 148, training accuracy 0.82\n",
      "step 149, training accuracy 0.88\n",
      "step 150, training accuracy 0.86\n",
      "step 151, training accuracy 0.92\n",
      "step 152, training accuracy 0.94\n",
      "step 153, training accuracy 0.86\n",
      "step 154, training accuracy 0.86\n",
      "step 155, training accuracy 0.82\n",
      "step 156, training accuracy 0.82\n",
      "step 157, training accuracy 0.86\n",
      "step 158, training accuracy 0.96\n",
      "step 159, training accuracy 0.82\n",
      "step 160, training accuracy 0.84\n",
      "step 161, training accuracy 0.9\n",
      "step 162, training accuracy 0.86\n",
      "step 163, training accuracy 0.88\n",
      "step 164, training accuracy 0.92\n",
      "step 165, training accuracy 0.84\n",
      "step 166, training accuracy 0.9\n",
      "step 167, training accuracy 0.86\n",
      "step 168, training accuracy 0.84\n",
      "step 169, training accuracy 0.92\n",
      "step 170, training accuracy 0.96\n",
      "step 171, training accuracy 0.9\n",
      "step 172, training accuracy 0.9\n",
      "step 173, training accuracy 0.88\n",
      "step 174, training accuracy 0.88\n",
      "step 175, training accuracy 0.9\n",
      "step 176, training accuracy 0.98\n",
      "step 177, training accuracy 0.86\n",
      "step 178, training accuracy 0.88\n",
      "step 179, training accuracy 0.9\n",
      "step 180, training accuracy 0.92\n",
      "step 181, training accuracy 0.88\n",
      "step 182, training accuracy 0.92\n",
      "step 183, training accuracy 0.94\n",
      "step 184, training accuracy 0.94\n",
      "step 185, training accuracy 0.88\n",
      "step 186, training accuracy 0.94\n",
      "step 187, training accuracy 0.88\n",
      "step 188, training accuracy 0.94\n",
      "step 189, training accuracy 0.94\n",
      "step 190, training accuracy 0.92\n",
      "step 191, training accuracy 0.9\n",
      "step 192, training accuracy 0.84\n",
      "step 193, training accuracy 0.88\n",
      "step 194, training accuracy 0.9\n",
      "step 195, training accuracy 0.92\n",
      "step 196, training accuracy 0.9\n",
      "step 197, training accuracy 0.98\n",
      "step 198, training accuracy 0.92\n",
      "step 199, training accuracy 0.94\n",
      "step 200, training accuracy 0.9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-8bbe37ab3257>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             test_acc = sess.run(accuracy, \n\u001b[1;32m---> 28\u001b[1;33m                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             )\n\u001b[0;32m     30\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test accuracy %g'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yangyangii\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yangyangii\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yangyangii\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yangyangii\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yangyangii\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yangyangii\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(\n",
    "#     tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logit)\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=labels)\n",
    ")\n",
    "train_op = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(logit, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "max_epoch = 1\n",
    "total_batch = int(mnist.train.num_examples/BATCH_SIZE)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(max_epoch):\n",
    "    for i in range(total_batch):\n",
    "        batch = mnist.train.next_batch(BATCH_SIZE, shuffle=True)\n",
    "        sess.run(train_op, \n",
    "             feed_dict={images: batch[0], labels: batch[1], keep_prob: 0.5}\n",
    "        )\n",
    "        train_acc = sess.run(accuracy,\n",
    "            feed_dict={images: batch[0], labels: batch[1], keep_prob: 1.0}\n",
    "        )\n",
    "        print('step %d, training accuracy %g' % (i, train_acc))\n",
    "        if i % 100 == 0:\n",
    "            test_acc = sess.run(accuracy, \n",
    "                 feed_dict={images: mnist.test.images, labels: mnist.test.labels, keep_prob: 1.0}\n",
    "            )\n",
    "            print('test accuracy %g' % test_acc)\n",
    "test_acc = sess.run(accuracy, \n",
    "     feed_dict={images: mnist.test.images, labels: mnist.test.labels, keep_prob: 1.0}\n",
    ")\n",
    "print('test accuracy %g' % test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss를 softmax와 cross entropy를 함께 처리해주는 함수를 통해 처리한다.\n",
    "\n",
    "학습 optimizer 함수는 여러가지가 있으나 AdamOptimizer가 잘 작동한다고 알려져 있으므로 이를 사용하고 learning rate는 적당히 작은 값인 0.0001을 사용한다.\n",
    "\n",
    "mini-batch size는 50으로 하고, 총 iteration은 500번으로 한다.\n",
    "\n",
    "drop out의 비율을 학습할 때는 0.5로 하여 절반을 drop시키고 실제 예측할 때는 1.0으로 하여 모두 켜두도록 한다.\n",
    "\n",
    "학습시 마다 training set의 accuracy를 확인하고, 100번째마다 test set의 accuracy를 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실습! 성능 높이기: 15분, epoch 1000 이내"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction w/ CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실습! Prediction 해보기: 10분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9klEQVR4nGNgoD9ghDG0rHUZgl/r\nX2Q4W/3zPZoilkd/YeDxKUk0ydS/f3//+DGl2zxi6Y+/wWiSRd8OmcPYX24IQ42DCqy+9v4kXOXP\n3zjdqPfjvjiExYQpacJ64iUOfWaHbx4WxiHX9fnvMT4ccsp7Hq0Twi6lNvPV/jIkPguyJLv0v2Ur\ncZipOsMUVQAe8AxeEg/vPsChzezTu3B0MZjOdLFnB+6iS0IcpLD5y9UrGHJQnUqXORj+nzrOcElv\ntehuSf+zq4R6qhFqwq/Dovr76v27//79e4obyU5B9UgGBj2zj6u/b9e88zeA4fGkXzhcTmMAAL7m\nZmt4PmtlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F3D51AD2DD8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = mnist.train.images[999:1000]\n",
    "print(np.argmax(mnist.train.labels[999]))\n",
    "scipy.misc.toimage(input_data[0].reshape((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Result: 2\n"
     ]
    }
   ],
   "source": [
    "pred = tf.argmax(logit, 1)\n",
    "result = sess.run(pred, feed_dict={images: input_data, keep_prob: 1.0})\n",
    "print('Prediction Result: {}'.format(result[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "숫자 2에 대한 이미지를 예측하고 결과를 보여주는 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard w/ CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape, name='weights'):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def bias_variable(shape, name='biases'):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv(x, W, name='conv'):\n",
    "    with tf.name_scope(name) as scope:\n",
    "        return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool(x, name='max_pool'):\n",
    "    with tf.name_scope(name) as scope:\n",
    "        return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "reshape_images = tf.reshape(images, [-1, 28, 28, 1])\n",
    "\n",
    "labels = tf.placeholder(shape=[None, 10], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5,5,1,32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "W_conv2 = weight_variable([5,5,32,64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "W_fc1 = weight_variable([7*7*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layer1 = tf.nn.relu(conv(reshape_images, W_conv1) + b_conv1)\n",
    "pool_layer1 = max_pool(conv_layer1)\n",
    "\n",
    "conv_layer2 = tf.nn.relu(conv(pool_layer1, W_conv2) + b_conv2)\n",
    "pool_layer2 = max_pool(conv_layer2)\n",
    "\n",
    "pool2_flat = tf.reshape(pool_layer2, [-1, 7*7*64])\n",
    "\n",
    "with tf.name_scope('fc_layer') as scope:\n",
    "    fc_layer1 = tf.nn.relu(tf.matmul(pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "with tf.name_scope('fc_layer') as scope:\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    drop_out = tf.nn.dropout(fc_layer1, keep_prob)\n",
    "    logit = tf.matmul(drop_out, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.12\n",
      "test accuracy 0.1019\n",
      "step 1, training accuracy 0.06\n",
      "step 2, training accuracy 0.08\n",
      "step 3, training accuracy 0.06\n",
      "step 4, training accuracy 0.12\n",
      "step 5, training accuracy 0.14\n",
      "step 6, training accuracy 0.2\n",
      "step 7, training accuracy 0.16\n",
      "step 8, training accuracy 0.16\n",
      "step 9, training accuracy 0.22\n",
      "step 10, training accuracy 0.2\n",
      "step 11, training accuracy 0.24\n",
      "step 12, training accuracy 0.2\n",
      "step 13, training accuracy 0.32\n",
      "step 14, training accuracy 0.26\n",
      "step 15, training accuracy 0.3\n",
      "step 16, training accuracy 0.4\n",
      "step 17, training accuracy 0.4\n",
      "step 18, training accuracy 0.56\n",
      "step 19, training accuracy 0.4\n",
      "step 20, training accuracy 0.4\n",
      "step 21, training accuracy 0.56\n",
      "step 22, training accuracy 0.52\n",
      "step 23, training accuracy 0.44\n",
      "step 24, training accuracy 0.5\n",
      "step 25, training accuracy 0.52\n",
      "step 26, training accuracy 0.56\n",
      "step 27, training accuracy 0.44\n",
      "step 28, training accuracy 0.46\n",
      "step 29, training accuracy 0.64\n",
      "step 30, training accuracy 0.5\n",
      "step 31, training accuracy 0.56\n",
      "step 32, training accuracy 0.64\n",
      "step 33, training accuracy 0.58\n",
      "step 34, training accuracy 0.64\n",
      "step 35, training accuracy 0.58\n",
      "step 36, training accuracy 0.66\n",
      "step 37, training accuracy 0.64\n",
      "step 38, training accuracy 0.6\n",
      "step 39, training accuracy 0.66\n",
      "step 40, training accuracy 0.76\n",
      "step 41, training accuracy 0.82\n",
      "step 42, training accuracy 0.68\n",
      "step 43, training accuracy 0.64\n",
      "step 44, training accuracy 0.66\n",
      "step 45, training accuracy 0.64\n",
      "step 46, training accuracy 0.78\n",
      "step 47, training accuracy 0.68\n",
      "step 48, training accuracy 0.72\n",
      "step 49, training accuracy 0.7\n",
      "step 50, training accuracy 0.66\n",
      "step 51, training accuracy 0.82\n",
      "step 52, training accuracy 0.7\n",
      "step 53, training accuracy 0.74\n",
      "step 54, training accuracy 0.84\n",
      "step 55, training accuracy 0.78\n",
      "step 56, training accuracy 0.72\n",
      "step 57, training accuracy 0.8\n",
      "step 58, training accuracy 0.78\n",
      "step 59, training accuracy 0.82\n",
      "step 60, training accuracy 0.8\n",
      "step 61, training accuracy 0.74\n",
      "step 62, training accuracy 0.74\n",
      "step 63, training accuracy 0.8\n",
      "step 64, training accuracy 0.76\n",
      "step 65, training accuracy 0.7\n",
      "step 66, training accuracy 0.72\n",
      "step 67, training accuracy 0.7\n",
      "step 68, training accuracy 0.78\n",
      "step 69, training accuracy 0.84\n",
      "step 70, training accuracy 0.8\n",
      "step 71, training accuracy 0.8\n",
      "step 72, training accuracy 0.74\n",
      "step 73, training accuracy 0.78\n",
      "step 74, training accuracy 0.78\n",
      "step 75, training accuracy 0.84\n",
      "step 76, training accuracy 0.82\n",
      "step 77, training accuracy 0.8\n",
      "step 78, training accuracy 0.84\n",
      "step 79, training accuracy 0.8\n",
      "step 80, training accuracy 0.84\n",
      "step 81, training accuracy 0.84\n",
      "step 82, training accuracy 0.88\n",
      "step 83, training accuracy 0.9\n",
      "step 84, training accuracy 0.76\n",
      "step 85, training accuracy 0.88\n",
      "step 86, training accuracy 0.84\n",
      "step 87, training accuracy 0.86\n",
      "step 88, training accuracy 0.76\n",
      "step 89, training accuracy 0.86\n",
      "step 90, training accuracy 0.88\n",
      "step 91, training accuracy 0.8\n",
      "step 92, training accuracy 0.84\n",
      "step 93, training accuracy 0.92\n",
      "step 94, training accuracy 0.8\n",
      "step 95, training accuracy 0.82\n",
      "step 96, training accuracy 0.8\n",
      "step 97, training accuracy 0.84\n",
      "step 98, training accuracy 0.84\n",
      "step 99, training accuracy 0.82\n",
      "step 100, training accuracy 0.82\n",
      "test accuracy 0.8508\n",
      "step 101, training accuracy 0.88\n",
      "step 102, training accuracy 0.78\n",
      "step 103, training accuracy 0.82\n",
      "step 104, training accuracy 0.84\n",
      "step 105, training accuracy 0.9\n",
      "step 106, training accuracy 0.82\n",
      "step 107, training accuracy 0.82\n",
      "step 108, training accuracy 0.8\n",
      "step 109, training accuracy 0.88\n",
      "step 110, training accuracy 0.92\n",
      "step 111, training accuracy 0.9\n",
      "step 112, training accuracy 0.86\n",
      "step 113, training accuracy 0.98\n",
      "step 114, training accuracy 0.78\n",
      "step 115, training accuracy 0.88\n",
      "step 116, training accuracy 0.8\n",
      "step 117, training accuracy 0.78\n",
      "step 118, training accuracy 0.9\n",
      "step 119, training accuracy 0.76\n",
      "step 120, training accuracy 0.84\n",
      "step 121, training accuracy 0.92\n",
      "step 122, training accuracy 0.9\n",
      "step 123, training accuracy 0.88\n",
      "step 124, training accuracy 0.88\n",
      "step 125, training accuracy 0.88\n",
      "step 126, training accuracy 0.9\n",
      "step 127, training accuracy 0.86\n",
      "step 128, training accuracy 0.86\n",
      "step 129, training accuracy 0.94\n",
      "step 130, training accuracy 0.84\n",
      "step 131, training accuracy 0.88\n",
      "step 132, training accuracy 0.74\n",
      "step 133, training accuracy 0.92\n",
      "step 134, training accuracy 0.86\n",
      "step 135, training accuracy 0.92\n",
      "step 136, training accuracy 0.92\n",
      "step 137, training accuracy 0.86\n",
      "step 138, training accuracy 0.9\n",
      "step 139, training accuracy 0.88\n",
      "step 140, training accuracy 0.82\n",
      "step 141, training accuracy 0.84\n",
      "step 142, training accuracy 0.82\n",
      "step 143, training accuracy 0.82\n",
      "step 144, training accuracy 0.88\n",
      "step 145, training accuracy 0.86\n",
      "step 146, training accuracy 0.82\n",
      "step 147, training accuracy 0.88\n",
      "step 148, training accuracy 0.94\n",
      "step 149, training accuracy 0.9\n",
      "step 150, training accuracy 0.84\n",
      "step 151, training accuracy 0.86\n",
      "step 152, training accuracy 0.88\n",
      "step 153, training accuracy 0.88\n",
      "step 154, training accuracy 0.86\n",
      "step 155, training accuracy 0.92\n",
      "step 156, training accuracy 0.94\n",
      "step 157, training accuracy 0.92\n",
      "step 158, training accuracy 0.9\n",
      "step 159, training accuracy 0.82\n",
      "step 160, training accuracy 0.9\n",
      "step 161, training accuracy 0.92\n",
      "step 162, training accuracy 0.9\n",
      "step 163, training accuracy 0.82\n",
      "step 164, training accuracy 0.92\n",
      "step 165, training accuracy 0.9\n",
      "step 166, training accuracy 0.84\n",
      "step 167, training accuracy 0.92\n",
      "step 168, training accuracy 0.84\n",
      "step 169, training accuracy 0.94\n",
      "step 170, training accuracy 0.96\n",
      "step 171, training accuracy 0.88\n",
      "step 172, training accuracy 0.92\n",
      "step 173, training accuracy 0.96\n",
      "step 174, training accuracy 0.94\n",
      "step 175, training accuracy 0.9\n",
      "step 176, training accuracy 0.82\n",
      "step 177, training accuracy 0.88\n",
      "step 178, training accuracy 0.92\n",
      "step 179, training accuracy 0.88\n",
      "step 180, training accuracy 0.96\n",
      "step 181, training accuracy 0.86\n",
      "step 182, training accuracy 0.8\n",
      "step 183, training accuracy 0.92\n",
      "step 184, training accuracy 0.94\n",
      "step 185, training accuracy 0.92\n",
      "step 186, training accuracy 0.88\n",
      "step 187, training accuracy 0.92\n",
      "step 188, training accuracy 0.94\n",
      "step 189, training accuracy 0.94\n",
      "step 190, training accuracy 0.94\n",
      "step 191, training accuracy 0.92\n",
      "step 192, training accuracy 0.94\n",
      "step 193, training accuracy 0.88\n",
      "step 194, training accuracy 0.9\n",
      "step 195, training accuracy 0.84\n",
      "step 196, training accuracy 0.92\n",
      "step 197, training accuracy 0.86\n",
      "step 198, training accuracy 0.88\n",
      "step 199, training accuracy 0.86\n",
      "step 200, training accuracy 0.92\n",
      "test accuracy 0.9001\n",
      "step 201, training accuracy 0.8\n",
      "step 202, training accuracy 0.82\n",
      "step 203, training accuracy 0.96\n",
      "step 204, training accuracy 0.94\n",
      "step 205, training accuracy 0.94\n",
      "step 206, training accuracy 0.86\n",
      "step 207, training accuracy 0.88\n",
      "step 208, training accuracy 0.9\n",
      "step 209, training accuracy 0.94\n",
      "step 210, training accuracy 0.98\n",
      "step 211, training accuracy 0.82\n",
      "step 212, training accuracy 0.9\n",
      "step 213, training accuracy 0.94\n",
      "step 214, training accuracy 0.94\n",
      "step 215, training accuracy 0.88\n",
      "step 216, training accuracy 0.94\n",
      "step 217, training accuracy 1\n",
      "step 218, training accuracy 0.94\n",
      "step 219, training accuracy 0.86\n",
      "step 220, training accuracy 0.88\n",
      "step 221, training accuracy 0.96\n",
      "step 222, training accuracy 0.92\n",
      "step 223, training accuracy 0.96\n",
      "step 224, training accuracy 0.92\n",
      "step 225, training accuracy 0.92\n",
      "step 226, training accuracy 0.94\n",
      "step 227, training accuracy 0.94\n",
      "step 228, training accuracy 0.92\n",
      "step 229, training accuracy 0.84\n",
      "step 230, training accuracy 0.92\n",
      "step 231, training accuracy 0.9\n",
      "step 232, training accuracy 0.94\n",
      "step 233, training accuracy 0.9\n",
      "step 234, training accuracy 0.92\n",
      "step 235, training accuracy 0.94\n",
      "step 236, training accuracy 0.86\n",
      "step 237, training accuracy 0.9\n",
      "step 238, training accuracy 0.92\n",
      "step 239, training accuracy 0.9\n",
      "step 240, training accuracy 0.9\n",
      "step 241, training accuracy 0.96\n",
      "step 242, training accuracy 0.9\n",
      "step 243, training accuracy 0.82\n",
      "step 244, training accuracy 0.98\n",
      "step 245, training accuracy 0.98\n",
      "step 246, training accuracy 0.92\n",
      "step 247, training accuracy 0.94\n",
      "step 248, training accuracy 0.86\n",
      "step 249, training accuracy 0.78\n",
      "step 250, training accuracy 0.9\n",
      "step 251, training accuracy 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 252, training accuracy 0.96\n",
      "step 253, training accuracy 0.98\n",
      "step 254, training accuracy 0.92\n",
      "step 255, training accuracy 0.92\n",
      "step 256, training accuracy 0.9\n",
      "step 257, training accuracy 0.94\n",
      "step 258, training accuracy 0.94\n",
      "step 259, training accuracy 0.88\n",
      "step 260, training accuracy 0.9\n",
      "step 261, training accuracy 0.92\n",
      "step 262, training accuracy 1\n",
      "step 263, training accuracy 0.88\n",
      "step 264, training accuracy 0.92\n",
      "step 265, training accuracy 0.94\n",
      "step 266, training accuracy 0.94\n",
      "step 267, training accuracy 0.86\n",
      "step 268, training accuracy 0.94\n",
      "step 269, training accuracy 0.92\n",
      "step 270, training accuracy 0.92\n",
      "step 271, training accuracy 0.92\n",
      "step 272, training accuracy 0.96\n",
      "step 273, training accuracy 0.96\n",
      "step 274, training accuracy 0.94\n",
      "step 275, training accuracy 0.94\n",
      "step 276, training accuracy 0.86\n",
      "step 277, training accuracy 0.96\n",
      "step 278, training accuracy 0.96\n",
      "step 279, training accuracy 0.88\n",
      "step 280, training accuracy 0.86\n",
      "step 281, training accuracy 0.96\n",
      "step 282, training accuracy 0.9\n",
      "step 283, training accuracy 0.92\n",
      "step 284, training accuracy 0.9\n",
      "step 285, training accuracy 0.98\n",
      "step 286, training accuracy 0.9\n",
      "step 287, training accuracy 0.92\n",
      "step 288, training accuracy 1\n",
      "step 289, training accuracy 0.9\n",
      "step 290, training accuracy 0.9\n",
      "step 291, training accuracy 0.9\n",
      "step 292, training accuracy 0.9\n",
      "step 293, training accuracy 0.88\n",
      "step 294, training accuracy 0.92\n",
      "step 295, training accuracy 0.94\n",
      "step 296, training accuracy 0.88\n",
      "step 297, training accuracy 0.92\n",
      "step 298, training accuracy 0.9\n",
      "step 299, training accuracy 0.92\n",
      "step 300, training accuracy 0.92\n",
      "test accuracy 0.9281\n",
      "step 301, training accuracy 0.84\n",
      "step 302, training accuracy 0.84\n",
      "step 303, training accuracy 0.94\n",
      "step 304, training accuracy 0.96\n",
      "step 305, training accuracy 0.88\n",
      "step 306, training accuracy 0.9\n",
      "step 307, training accuracy 0.92\n",
      "step 308, training accuracy 0.9\n",
      "step 309, training accuracy 0.94\n",
      "step 310, training accuracy 0.88\n",
      "step 311, training accuracy 0.9\n",
      "step 312, training accuracy 0.92\n",
      "step 313, training accuracy 0.96\n",
      "step 314, training accuracy 0.94\n",
      "step 315, training accuracy 0.92\n",
      "step 316, training accuracy 0.86\n",
      "step 317, training accuracy 0.98\n",
      "step 318, training accuracy 0.94\n",
      "step 319, training accuracy 0.84\n",
      "step 320, training accuracy 0.92\n",
      "step 321, training accuracy 0.92\n",
      "step 322, training accuracy 0.94\n",
      "step 323, training accuracy 0.92\n",
      "step 324, training accuracy 0.92\n",
      "step 325, training accuracy 0.98\n",
      "step 326, training accuracy 0.96\n",
      "step 327, training accuracy 0.86\n",
      "step 328, training accuracy 0.9\n",
      "step 329, training accuracy 0.94\n",
      "step 330, training accuracy 0.88\n",
      "step 331, training accuracy 0.96\n",
      "step 332, training accuracy 0.96\n",
      "step 333, training accuracy 0.98\n",
      "step 334, training accuracy 0.96\n",
      "step 335, training accuracy 0.88\n",
      "step 336, training accuracy 0.96\n",
      "step 337, training accuracy 0.92\n",
      "step 338, training accuracy 0.94\n",
      "step 339, training accuracy 0.92\n",
      "step 340, training accuracy 0.98\n",
      "step 341, training accuracy 1\n",
      "step 342, training accuracy 0.94\n",
      "step 343, training accuracy 0.92\n",
      "step 344, training accuracy 0.98\n",
      "step 345, training accuracy 0.96\n",
      "step 346, training accuracy 0.96\n",
      "step 347, training accuracy 0.88\n",
      "step 348, training accuracy 0.94\n",
      "step 349, training accuracy 0.98\n",
      "step 350, training accuracy 0.92\n",
      "step 351, training accuracy 0.9\n",
      "step 352, training accuracy 0.84\n",
      "step 353, training accuracy 0.96\n",
      "step 354, training accuracy 0.88\n",
      "step 355, training accuracy 1\n",
      "step 356, training accuracy 0.96\n",
      "step 357, training accuracy 0.98\n",
      "step 358, training accuracy 0.92\n",
      "step 359, training accuracy 0.92\n",
      "step 360, training accuracy 0.92\n",
      "step 361, training accuracy 0.98\n",
      "step 362, training accuracy 0.9\n",
      "step 363, training accuracy 0.96\n",
      "step 364, training accuracy 0.96\n",
      "step 365, training accuracy 0.98\n",
      "step 366, training accuracy 0.96\n",
      "step 367, training accuracy 0.94\n",
      "step 368, training accuracy 0.92\n",
      "step 369, training accuracy 0.98\n",
      "step 370, training accuracy 0.92\n",
      "step 371, training accuracy 0.88\n",
      "step 372, training accuracy 0.84\n",
      "step 373, training accuracy 0.9\n",
      "step 374, training accuracy 0.94\n",
      "step 375, training accuracy 0.96\n",
      "step 376, training accuracy 0.94\n",
      "step 377, training accuracy 0.9\n",
      "step 378, training accuracy 0.94\n",
      "step 379, training accuracy 0.92\n",
      "step 380, training accuracy 0.98\n",
      "step 381, training accuracy 0.94\n",
      "step 382, training accuracy 0.98\n",
      "step 383, training accuracy 0.98\n",
      "step 384, training accuracy 0.96\n",
      "step 385, training accuracy 0.96\n",
      "step 386, training accuracy 0.94\n",
      "step 387, training accuracy 0.98\n",
      "step 388, training accuracy 0.94\n",
      "step 389, training accuracy 0.98\n",
      "step 390, training accuracy 0.9\n",
      "step 391, training accuracy 0.96\n",
      "step 392, training accuracy 0.82\n",
      "step 393, training accuracy 0.9\n",
      "step 394, training accuracy 0.94\n",
      "step 395, training accuracy 0.9\n",
      "step 396, training accuracy 0.96\n",
      "step 397, training accuracy 0.94\n",
      "step 398, training accuracy 0.88\n",
      "step 399, training accuracy 0.9\n",
      "step 400, training accuracy 0.9\n",
      "test accuracy 0.934\n",
      "step 401, training accuracy 0.94\n",
      "step 402, training accuracy 0.88\n",
      "step 403, training accuracy 0.96\n",
      "step 404, training accuracy 0.94\n",
      "step 405, training accuracy 0.96\n",
      "step 406, training accuracy 1\n",
      "step 407, training accuracy 0.98\n",
      "step 408, training accuracy 0.9\n",
      "step 409, training accuracy 0.88\n",
      "step 410, training accuracy 0.92\n",
      "step 411, training accuracy 0.92\n",
      "step 412, training accuracy 0.92\n",
      "step 413, training accuracy 0.94\n",
      "step 414, training accuracy 0.88\n",
      "step 415, training accuracy 0.92\n",
      "step 416, training accuracy 0.94\n",
      "step 417, training accuracy 0.92\n",
      "step 418, training accuracy 0.94\n",
      "step 419, training accuracy 0.88\n",
      "step 420, training accuracy 0.9\n",
      "step 421, training accuracy 0.96\n",
      "step 422, training accuracy 0.88\n",
      "step 423, training accuracy 0.96\n",
      "step 424, training accuracy 0.88\n",
      "step 425, training accuracy 0.96\n",
      "step 426, training accuracy 0.92\n",
      "step 427, training accuracy 0.94\n",
      "step 428, training accuracy 0.92\n",
      "step 429, training accuracy 0.92\n",
      "step 430, training accuracy 0.88\n",
      "step 431, training accuracy 0.94\n",
      "step 432, training accuracy 0.96\n",
      "step 433, training accuracy 0.96\n",
      "step 434, training accuracy 0.82\n",
      "step 435, training accuracy 0.96\n",
      "step 436, training accuracy 0.94\n",
      "step 437, training accuracy 0.98\n",
      "step 438, training accuracy 0.98\n",
      "step 439, training accuracy 0.98\n",
      "step 440, training accuracy 0.96\n",
      "step 441, training accuracy 0.98\n",
      "step 442, training accuracy 0.96\n",
      "step 443, training accuracy 0.98\n",
      "step 444, training accuracy 0.94\n",
      "step 445, training accuracy 0.98\n",
      "step 446, training accuracy 0.86\n",
      "step 447, training accuracy 0.94\n",
      "step 448, training accuracy 0.96\n",
      "step 449, training accuracy 0.92\n",
      "step 450, training accuracy 0.94\n",
      "step 451, training accuracy 0.98\n",
      "step 452, training accuracy 0.94\n",
      "step 453, training accuracy 1\n",
      "step 454, training accuracy 0.88\n",
      "step 455, training accuracy 0.98\n",
      "step 456, training accuracy 0.98\n",
      "step 457, training accuracy 1\n",
      "step 458, training accuracy 0.92\n",
      "step 459, training accuracy 1\n",
      "step 460, training accuracy 0.9\n",
      "step 461, training accuracy 1\n",
      "step 462, training accuracy 0.92\n",
      "step 463, training accuracy 0.98\n",
      "step 464, training accuracy 0.98\n",
      "step 465, training accuracy 0.98\n",
      "step 466, training accuracy 0.9\n",
      "step 467, training accuracy 1\n",
      "step 468, training accuracy 0.92\n",
      "step 469, training accuracy 0.9\n",
      "step 470, training accuracy 0.98\n",
      "step 471, training accuracy 0.94\n",
      "step 472, training accuracy 0.94\n",
      "step 473, training accuracy 0.9\n",
      "step 474, training accuracy 0.96\n",
      "step 475, training accuracy 0.96\n",
      "step 476, training accuracy 0.98\n",
      "step 477, training accuracy 0.9\n",
      "step 478, training accuracy 0.92\n",
      "step 479, training accuracy 0.94\n",
      "step 480, training accuracy 0.94\n",
      "step 481, training accuracy 0.94\n",
      "step 482, training accuracy 0.92\n",
      "step 483, training accuracy 0.98\n",
      "step 484, training accuracy 0.96\n",
      "step 485, training accuracy 0.96\n",
      "step 486, training accuracy 0.94\n",
      "step 487, training accuracy 0.96\n",
      "step 488, training accuracy 0.96\n",
      "step 489, training accuracy 0.98\n",
      "step 490, training accuracy 1\n",
      "step 491, training accuracy 0.98\n",
      "step 492, training accuracy 1\n",
      "step 493, training accuracy 0.96\n",
      "step 494, training accuracy 0.94\n",
      "step 495, training accuracy 0.96\n",
      "step 496, training accuracy 1\n",
      "step 497, training accuracy 0.94\n",
      "step 498, training accuracy 0.94\n",
      "step 499, training accuracy 0.84\n",
      "test accuracy 0.9397\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logit)\n",
    ")\n",
    "train_op = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(logit, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "tf.summary.image('images', reshape_images)\n",
    "tf.summary.scalar('xentropy', loss)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "max_epoch = 5\n",
    "total_batch = int(mnist.train.num_examples/BATCH_SIZE)\n",
    "# with tf.Session() as sess:\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "test_writer = tf.summary.FileWriter('./test', sess.graph)\n",
    "for epoch in range(max_epoch):\n",
    "    for i in range(total_batch):\n",
    "        batch = mnist.train.next_batch(50, shuffle=True)\n",
    "        sess.run(train_op, \n",
    "             feed_dict={images: batch[0], labels: batch[1], keep_prob: 0.5}\n",
    "        )\n",
    "        train_acc = sess.run(accuracy,\n",
    "            feed_dict={images: batch[0], labels: batch[1], keep_prob: 1.0}\n",
    "        )\n",
    "        print('step %d, training accuracy %g' % (i, train_acc))\n",
    "        if i % 100 == 0:\n",
    "            test_acc, summary = sess.run([accuracy, merged], \n",
    "                 feed_dict={images: mnist.test.images, labels: mnist.test.labels, keep_prob: 1.0}\n",
    "            )\n",
    "            print('test accuracy %g' % test_acc)\n",
    "            test_writer.add_summary(summary, i)\n",
    "test_acc, summary = sess.run([accuracy, merged], \n",
    "     feed_dict={images: mnist.test.images, labels: mnist.test.labels, keep_prob: 1.0}\n",
    ")\n",
    "print('test accuracy %g' % test_acc)\n",
    "test_writer.add_summary(summary, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\n\\x0f\\n\\x08xentropy\\x15~\\x8d+>\\n\\x0f\\n\\x08accuracy\\x158\\xf8r?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard를 통해 중요한 요소들을 기록하는 코드를 추가했다.\n",
    "가장 먼저 loss가 정상적으로 줄어드는지 확인하기 위해 추가하되, loss는 스칼라값이므로 tf.summary.scalar를 통해 기록한다. 이 때 앞에 있는 parameter는 기록할 name이다.\n",
    "accuracy 또한 iteration마다 어떻게 증가하는지 확인하기 위해 기록한다.\n",
    "\n",
    "tf.summary.merge_all 함수는 tf.summary를 통해 기록하기 위해 넣은 operation을 모두 병합하여 실행하는 함수다. tf.summary.FileWriter는 기록한 내용을 파일에 쓰는 함수이다. 원하는 폴더를 argument로 넘겨주면 된다. 우리는 test set에 대한 스칼라값만 기록할 것이므로 test 폴더에 기록한다.\n",
    "\n",
    "sess.run을 통해 test set의 accuracy operation을 실행할 때, merged operation도 함께 실행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파일에 기록한 summary를 TensorBoard로 확인하기 위해서는 해당 폴더에 접근하여,\n",
    "\n",
    "~\\test> tensorboard --logdir=.\n",
    "\n",
    "위 명령어를 입력하면 된다.\n",
    "그럼 웹브라우저에서 http://localhost:6006 를 통해 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
